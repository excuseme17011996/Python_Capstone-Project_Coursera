WEBVTT

1
00:00:09.147 --> 00:00:13.157
So, to review, we did our two to three
day process that sort of pulled all this

2
00:00:13.157 --> 00:00:14.530
data off the internet.

3
00:00:14.530 --> 00:00:19.240
Hopefully, you haven't crashed your home
bandwidth, or crashed anybody's bandwidth.

4
00:00:19.240 --> 00:00:20.950
You don't have to do all of this.

5
00:00:20.950 --> 00:00:23.450
If you're only going to do a little
bit you can play with the word stuff.

6
00:00:23.450 --> 00:00:26.193
The lines aren't going to look good
with a small amount of data but

7
00:00:26.193 --> 00:00:27.807
this is two to three days worth of work.

8
00:00:27.807 --> 00:00:31.204
And that is a restartable process
it's kind of a spider process,

9
00:00:31.204 --> 00:00:33.020
focus on restartability.

10
00:00:33.020 --> 00:00:35.350
Then we ran this gmodel
which cleans the data up,

11
00:00:35.350 --> 00:00:38.340
makes it much smaller,
makes it actually relational.

12
00:00:38.340 --> 00:00:41.980
So we have multiple tables connected
together by foreign keys and

13
00:00:41.980 --> 00:00:45.540
now we're going to talk about these
next few steps in the visualization.

14
00:00:46.540 --> 00:00:50.280
So this is where the fact that this data
is all beautifully relational is going to

15
00:00:50.280 --> 00:00:51.670
pay off for us.

16
00:00:51.670 --> 00:00:56.415
And so we're going to start with the
gbasic.py just so we can take a look at

17
00:00:56.415 --> 00:01:01.097
how the code loops through and
just treats the database as input data.

18
00:01:01.097 --> 00:01:08.050
And it looks a lot like things we've been
doing all along, gbasic, right there.

19
00:01:08.050 --> 00:01:11.310
It looks like the things we've been doing
all along except that we have a select at

20
00:01:11.310 --> 00:01:11.950
the beginning.

21
00:01:11.950 --> 00:01:17.180
So we can think of this as we're going to
make a connection to the database and

22
00:01:17.180 --> 00:01:18.020
we're going to run a select.

23
00:01:18.020 --> 00:01:21.760
And we're going to join between, in this
case, the messages and the senders so

24
00:01:21.760 --> 00:01:24.120
that we can get the sender's name, right?

25
00:01:24.120 --> 00:01:26.950
And so that's the real value here
is we're going to loop through all

26
00:01:26.950 --> 00:01:31.350
the different senders in the database and
then run a count on those folks.

27
00:01:31.350 --> 00:01:34.090
And from here on,
other than the fact that this

28
00:01:34.090 --> 00:01:37.740
for loop is going through
each row in the cursor

29
00:01:37.740 --> 00:01:41.960
and the sub zero is the message ID and
the sub one is the sender's

30
00:01:41.960 --> 00:01:44.752
email address and then we're going to
have some dictionaries, right?

31
00:01:44.752 --> 00:01:50.130
sendcounts = dict for dictionary to create
it with a constructor and message sub one,

32
00:01:50.130 --> 00:01:54.490
which is the second thing in that
select statement is our email address.

33
00:01:54.490 --> 00:01:57.630
And also note if you go back to gmodel we

34
00:01:57.630 --> 00:02:01.750
had all these weird email addresses that
had strange at signs and gmane in them.

35
00:02:01.750 --> 00:02:03.010
We cleaned all that up, and so

36
00:02:03.010 --> 00:02:07.680
this data that we're working with is
the index.sqlite which is clean data, so

37
00:02:07.680 --> 00:02:09.750
we can write really clean
loops that are simple.

38
00:02:09.750 --> 00:02:11.210
We know the data's been cleaned up.

39
00:02:11.210 --> 00:02:14.470
If we have to go clean it up, we go
back and re-clean the whole data up and

40
00:02:14.470 --> 00:02:16.010
run gmodel again.

41
00:02:16.010 --> 00:02:18.130
So we got the good email address,
it's clean.

42
00:02:18.130 --> 00:02:20.930
Whatever mapping we've done,
it's all done.

43
00:02:20.930 --> 00:02:24.173
And so then I'm just going to write,
sendcounts equals

44
00:02:24.173 --> 00:02:29.380
sendcounts.get(sender,0), I'm adding
one to it, a histogram bucket.

45
00:02:29.380 --> 00:02:33.630
Then we'll split that in the name and
email address and then name and

46
00:02:33.630 --> 00:02:37.110
domain name and
we get the second piece of that.

47
00:02:37.110 --> 00:02:40.570
And then we keep track
of the organizations.

48
00:02:40.570 --> 00:02:46.305
And that's really not that different
than code we've been writing all along.

49
00:02:46.305 --> 00:02:48.900
So we're going to do
some number of the top.

50
00:02:48.900 --> 00:02:50.700
We ask for this how many?

51
00:02:50.700 --> 00:02:51.710
Then we're going to sort it.

52
00:02:51.710 --> 00:02:53.120
So this sort is a little bit different.

53
00:02:53.120 --> 00:02:59.060
What we're going to do is sort
the sendcounts dictionary and

54
00:02:59.060 --> 00:03:04.690
use, as its sort key, the get for
each of the things, the get method.

55
00:03:04.690 --> 00:03:06.720
And that'll be the key upon which to sort.

56
00:03:06.720 --> 00:03:10.640
And then we're going to get back a list,
and that is a list of the counts.

57
00:03:10.640 --> 00:03:15.330
And so we're going to print the top
however many, going to have the key and

58
00:03:15.330 --> 00:03:17.690
then counts for that key.

59
00:03:17.690 --> 00:03:18.280
And then we're done.

60
00:03:18.280 --> 00:03:22.992
And we're going to do the same thing for
the organizations by sorting

61
00:03:22.992 --> 00:03:27.380
the organizations dictionary
by the value that's in there.

62
00:03:27.380 --> 00:03:29.340
And then we're going to
print the top ten of those.

63
00:03:29.340 --> 00:03:31.470
So this is pretty straightforward.

64
00:03:31.470 --> 00:03:36.330
So, print gbasic.py.

65
00:03:36.330 --> 00:03:43.020
Oops, print python gbasic.py.

66
00:03:43.020 --> 00:03:45.800
Let's just dump the top ten.

67
00:03:45.800 --> 00:03:47.710
And so you notice how instant that was,
right?

68
00:03:47.710 --> 00:03:49.310
That read the whole database.

69
00:03:49.310 --> 00:03:51.870
That literally read everything
in that database and

70
00:03:51.870 --> 00:03:54.740
that's the beauty of having
a fully relational database.

71
00:03:54.740 --> 00:03:58.630
If you remember, gmodel took eight,
ten minutes, maybe three minutes,

72
00:03:58.630 --> 00:04:01.190
maybe 20 minutes, depending on
how efficient your computer is.

73
00:04:01.190 --> 00:04:03.340
But this is super fast
because we did a select and

74
00:04:03.340 --> 00:04:06.110
a join and that's what databases 
are really good for.

75
00:04:06.110 --> 00:04:10.780
So this is a situation where you use this
multistep process so that the analysis

76
00:04:10.780 --> 00:04:13.760
you're going to do over and over and
over again happens really fast.

77
00:04:13.760 --> 00:04:17.750
And so that's why you did those two
slower steps. You wouldn't want to do

78
00:04:17.750 --> 00:04:20.686
data analysis and let it run for
three days just to get this list.

79
00:04:20.686 --> 00:04:22.900
Because now if want to change the code and

80
00:04:22.900 --> 00:04:24.980
get a different thing I
can just run it again.

81
00:04:24.980 --> 00:04:28.660
And while I want to dump 5 this time and
then bing it's that fast, right?

82
00:04:28.660 --> 00:04:31.550
So that's why you have this multi-step
process for your data.

83
00:04:32.730 --> 00:04:37.720
Okay, so that is just gbasic.

84
00:04:37.720 --> 00:04:41.160
Let's go ahead and take a look at
the next thing we're going to do and

85
00:04:41.160 --> 00:04:44.030
that is looking for the words.

86
00:04:44.030 --> 00:04:46.770
And you'll see that this
is a very similar pattern.

87
00:04:46.770 --> 00:04:50.260
We're going to effectively
grab index.sqlite.

88
00:04:50.260 --> 00:04:54.640
We're going to look at all the words in
the subject lines of all the messages.

89
00:04:54.640 --> 00:04:57.940
So we're going to select the subject and
subject id for

90
00:04:57.940 --> 00:04:59.855
messages joined on subject.

91
00:04:59.855 --> 00:05:03.840
because you recall, subjects are in
their own separate database, and

92
00:05:03.840 --> 00:05:04.840
then join that together.

93
00:05:04.840 --> 00:05:06.980
And then we're going to have a count.

94
00:05:06.980 --> 00:05:08.400
These are going to be a count of words,

95
00:05:08.400 --> 00:05:11.610
not the count of whole subject because
the subject is multiple words.

96
00:05:11.610 --> 00:05:15.790
We're going to pull out the text out of
the second parameter which is the actual

97
00:05:15.790 --> 00:05:16.735
subject itself.

98
00:05:16.735 --> 00:05:21.630
And we're going to use text translate
which is sting.punctuation, which is

99
00:05:21.630 --> 00:05:26.740
effectively just taking all commas and
exclamation points and underscores.

100
00:05:26.740 --> 00:05:30.020
All the punctuation is being taken out
of it, that's what this is doing.

101
00:05:30.020 --> 00:05:33.670
It's effectively a multiple replace
of everything in this string.

102
00:05:33.670 --> 00:05:35.650
Every character in this string
replacing it with nothing.

103
00:05:35.650 --> 00:05:38.510
And we're going to throw away all the
numbers, so we're going to replace this.

104
00:05:38.510 --> 00:05:41.730
We did this in an earlier
example with Romeo,

105
00:05:41.730 --> 00:05:45.620
where we were getting rid of anything
like trunk punctuation numbers.

106
00:05:45.620 --> 00:05:50.070
So at this point, this text variable is
the same as what was in the subject line

107
00:05:50.070 --> 00:05:53.440
except no punctuation and
no numbers in it.

108
00:05:53.440 --> 00:05:54.490
Now we're going to strip it,

109
00:05:54.490 --> 00:05:57.650
map to lowercase because we want this
words to match whenever possible.

110
00:05:57.650 --> 00:05:59.560
And then we're just going to use split.

111
00:05:59.560 --> 00:06:04.190
And at that point you have subject line,
no punctuation lowercase, and

112
00:06:04.190 --> 00:06:07.020
then we will do a simple
looping through the words.

113
00:06:07.020 --> 00:06:10.200
We aren't going to ask for words less
than four, we just skip those and

114
00:06:10.200 --> 00:06:13.100
then we're going to do
a simple count of the words.

115
00:06:13.100 --> 00:06:17.050
And again, we're going to find now
using the sorted with key = counts.get,

116
00:06:17.050 --> 00:06:23.580
that's basically saying don't go with the
key name itself but go with the key value.

117
00:06:23.580 --> 00:06:24.850
The value for a particular key,

118
00:06:24.850 --> 00:06:28.480
as the sorting thing. We still get
the keys back in this words thing.

119
00:06:28.480 --> 00:06:29.830
So that's all the different keys but

120
00:06:29.830 --> 00:06:32.340
now we're going to be able
to get the top hundred.

121
00:06:32.340 --> 00:06:34.580
And now we're going to look for

122
00:06:34.580 --> 00:06:38.110
the words in the top hundred that
have the highest and lowest count.

123
00:06:38.110 --> 00:06:42.590
And so this is just looping
through all the keys the 100 most

124
00:06:42.590 --> 00:06:46.620
common words and a simple high low loop.

125
00:06:46.620 --> 00:06:51.040
And when we have this, this ends up being
the range of the counts which is the most

126
00:06:51.040 --> 00:06:53.900
common word and the least common
words in the top 100 words.

127
00:06:53.900 --> 00:06:55.950
Okay, so that's what that showing for
us on line 35.

128
00:06:55.950 --> 00:06:59.190
And then what we're going to do is
we're going to produce some data.

129
00:06:59.190 --> 00:07:02.720
So this one. Let me show you real
quick what it's going to run like.

130
00:07:02.720 --> 00:07:09.210
So if I say python gword.py this
produces output to gword.js and

131
00:07:09.210 --> 00:07:14.048
I can open in my browser.
It turns out on Macintoshes I

132
00:07:14.048 --> 00:07:19.133
can just open a browser
by saying open gword.htm.

133
00:07:21.073 --> 00:07:24.210
and we're making this.

134
00:07:24.210 --> 00:07:26.240
And so I'm only taking a 100 words and

135
00:07:26.240 --> 00:07:30.190
what I have to do is based on the count
I want the size of these words to go

136
00:07:30.190 --> 00:07:35.130
from 20 point font to 80 point font
sort of relative to the size, okay?

137
00:07:35.130 --> 00:07:37.470
Of the words in the subject line.

138
00:07:37.470 --> 00:07:41.450
And so this is just a little
bit of kind of clever code.

139
00:07:41.450 --> 00:07:45.020
I'm writing this JavaScript file,
it's going to look like this.

140
00:07:45.020 --> 00:07:49.480
Which is just this has to do
with a d3.js visiualization and

141
00:07:49.480 --> 00:07:53.970
it's just the rules for the you know
what size we want this thing to do

142
00:07:53.970 --> 00:07:55.314
what font we want it to be

143
00:07:55.314 --> 00:07:58.078
Sakai we want it to be in font 100.

144
00:07:58.078 --> 00:08:00.630
Error we want it to be in font 22.

145
00:08:00.630 --> 00:08:02.960
That's the output that we're producing.

146
00:08:02.960 --> 00:08:07.240
And so we basically have,
the highest counts are going,

147
00:08:07.240 --> 00:08:10.530
the font size is between 20 and
100, based on the count.

148
00:08:10.530 --> 00:08:12.830
So we're going to write this file out and

149
00:08:12.830 --> 00:08:14.380
this is some of the syntax
we're going to write.

150
00:08:14.380 --> 00:08:18.470
So we're going to go through
the first 100 words and

151
00:08:18.470 --> 00:08:20.550
part of this is to get
the newlines right.

152
00:08:20.550 --> 00:08:23.590
It's really just to sort of get this
file to look the way we want it to.

153
00:08:25.400 --> 00:08:30.520
And grab the size and
then we're going to take the size and

154
00:08:31.670 --> 00:08:33.850
because we have the range of the size.

155
00:08:33.850 --> 00:08:38.860
The number of times this word was
mentioned, that's this, compared to,

156
00:08:38.860 --> 00:08:41.790
we'll subtract from the lowest and

157
00:08:41.790 --> 00:08:46.200
then we're going to divide between the
highest and lowest, and that's the range.

158
00:08:46.200 --> 00:08:47.930
We're going to divide by the range, and

159
00:08:47.930 --> 00:08:54.000
then we're going to multiply that number
times the big size plus the small size.

160
00:08:54.000 --> 00:08:57.870
So it's going to go from
sort of zero to 80 plus 20.

161
00:08:57.870 --> 00:08:59.870
And so it's going to be from 20 to 100.

162
00:08:59.870 --> 00:09:01.880
Ultimately this goes from 20 to 100.

163
00:09:01.880 --> 00:09:06.470
The largest one will be 100, the smallest
one will be 20 and they'll all spread out.

164
00:09:06.470 --> 00:09:09.830
So if you look, the largest,
the most common word is 100 font.

165
00:09:09.830 --> 00:09:14.835
This is the font we're trying to set and
71, 26, there's a lot low and

166
00:09:14.835 --> 00:09:18.580
then 20 are the lowest,
the words that are very rare.

167
00:09:18.580 --> 00:09:25.179
And then in this gword.html, we see that.

168
00:09:25.179 --> 00:09:28.873
And so we see the big words, the medium
sized words, the sort of almost small

169
00:09:28.873 --> 00:09:32.400
words, and then the really tiny words,
and that's how that works.

170
00:09:32.400 --> 00:09:34.280
And I'll just take a real quick look.

171
00:09:34.280 --> 00:09:36.880
This is not the html class, but

172
00:09:36.880 --> 00:09:42.360
this is just code that I got from
the d3js word cloud example.

173
00:09:42.360 --> 00:09:44.965
And all this I really just
took from their website.

174
00:09:44.965 --> 00:09:48.710
Make it the cloud, make it the cloud,
where's this somewhere in here,

175
00:09:48.710 --> 00:09:49.400
we're going to get the data.

176
00:09:49.400 --> 00:09:51.676
Somewhere there's the data.

177
00:09:53.937 --> 00:09:58.087
It's right here,
jword.gs is being included there and

178
00:09:58.087 --> 00:10:02.100
then it's going to end up in
that variable called gword.

179
00:10:02.100 --> 00:10:06.840
So somewhere in here,
it is looping though all of the words and

180
00:10:06.840 --> 00:10:08.300
producing these little pictures.

181
00:10:08.300 --> 00:10:10.380
So, we're not going to cover that.

182
00:10:10.380 --> 00:10:15.620
So that is a simple way to
go through the data and

183
00:10:15.620 --> 00:10:18.950
do a simple count and
then turned it into a word cloud.

184
00:10:18.950 --> 00:10:22.960
And sometimes you might build this word
cloud not just to make a word cloud but

185
00:10:22.960 --> 00:10:26.200
a visualization is often a way
to give you sanity on your data.

186
00:10:26.200 --> 00:10:28.770
You might make a word cloud out of
people's email address and have

187
00:10:28.770 --> 00:10:30.000
things stick out.

188
00:10:30.000 --> 00:10:34.500
It's just a interesting way to again,
visualization sometimes is not just to

189
00:10:34.500 --> 00:10:39.100
present something but for you to look at
your data and even debug the data, okay?

190
00:10:39.100 --> 00:10:41.810
So up next, we're going to do
our biggest visualization.