WEBVTT

1
00:00:09.083 --> 00:00:12.840
Okay, so now what we have is this
content.sqlite is in good shape.

2
00:00:12.840 --> 00:00:18.000
So we have got it. And the beautiful thing
is you can run the rest of this process.

3
00:00:18.000 --> 00:00:21.980
And then go back and Google, and go back
and scan some more stuff, it's okay.

4
00:00:21.980 --> 00:00:25.550
So you don't have to wait till you're all
done, you just run this other process.

5
00:00:25.550 --> 00:00:27.580
So, the thing we're
going to talk about next

6
00:00:27.580 --> 00:00:31.832
is the transformation from
content.sqlite to index.sqlite.

7
00:00:31.832 --> 00:00:35.570
So this is very raw,
and this is very clean.

8
00:00:37.300 --> 00:00:38.820
So this is raw and large and

9
00:00:38.820 --> 00:00:43.540
this is clean and small,
because we're going to read it many times.

10
00:00:43.540 --> 00:00:47.290
And so we have this process called
gmodel, I just happened to call it this,

11
00:00:47.290 --> 00:00:51.580
which makes the database
model go from ugly to clean.

12
00:00:51.580 --> 00:00:56.155
And one of the problems we have to solve
is read this file called mapping.sqlite,

13
00:00:56.155 --> 00:00:59.210
and this is where the people's
email addresses have changed.

14
00:00:59.210 --> 00:01:04.330
And sometimes an organization will change
its email address for the organization.

15
00:01:04.330 --> 00:01:10.810
Go from like mail.ites.umiss.edu to
mail.umiss.edu over a five-year period.

16
00:01:10.810 --> 00:01:13.610
So organizations even
change their email address.

17
00:01:13.610 --> 00:01:14.880
So we have got to clean this data up.

18
00:01:19.490 --> 00:01:22.980
You could think of this as like
a general cleaning up of step.

19
00:01:22.980 --> 00:01:25.150
Okay, so let's take a look at gmodel.py.

20
00:01:25.150 --> 00:01:27.820
And we won't look at all of the cleaning.

21
00:01:27.820 --> 00:01:30.930
It took me a long time to write this code.

22
00:01:30.930 --> 00:01:33.620
I'd run it, I would visualize it,
I would see some anomaly and

23
00:01:33.620 --> 00:01:35.760
then I would go change the mapping.

24
00:01:35.760 --> 00:01:41.540
And find things and use the visualization
to help me realize that, oh

25
00:01:41.540 --> 00:01:44.970
this person's showing up two times because
they have two different email addresses.

26
00:01:44.970 --> 00:01:49.720
Go back, modify the mapping.sqlite and
then run this process again and

27
00:01:49.720 --> 00:01:51.320
then run the visualization again.

28
00:01:51.320 --> 00:01:55.970
So I'd tend to find some mistake in this,
where one university would drop to zero.

29
00:01:55.970 --> 00:01:57.450
And a different university
would come up and

30
00:01:57.450 --> 00:01:59.830
it turned out they were the same
university, or whatever.

31
00:01:59.830 --> 00:02:02.380
And so
you tend to use your visualization and

32
00:02:02.380 --> 00:02:05.320
other visualizations to help you
figure out the cleaning of the data or

33
00:02:05.320 --> 00:02:08.980
this gbasic.py that I'll show you
to just dump what's going on.

34
00:02:08.980 --> 00:02:09.510
Oh, wait a sec.

35
00:02:09.510 --> 00:02:11.590
How come this person shows up five times?

36
00:02:11.590 --> 00:02:13.850
But okay, we're going to look at this.

37
00:02:13.850 --> 00:02:16.260
It is informed by a mapping file.

38
00:02:16.260 --> 00:02:18.100
It reads through every record in here and

39
00:02:18.100 --> 00:02:22.770
then produces a nicely data
modeled version of that same data.

40
00:02:24.320 --> 00:02:28.080
So we're going to start by
looking at gmodel.py, okay?

41
00:02:28.080 --> 00:02:28.730
So here we go.

42
00:02:30.100 --> 00:02:30.900
It's going to read through.

43
00:02:30.900 --> 00:02:32.980
Let's just skim it,
it's got some parsing in here.

44
00:02:32.980 --> 00:02:34.502
We're not going to cover that too much.

45
00:02:37.498 --> 00:02:40.140
Okay, so, we're going to start out.

46
00:02:42.290 --> 00:02:45.560
And this is an example of something
because there's code that doesn't work on

47
00:02:45.560 --> 00:02:46.330
some systems.

48
00:02:46.330 --> 00:02:48.460
We're going to have this mapping file but

49
00:02:48.460 --> 00:02:52.100
we're going to pull those mappings
into a dictionary from a database.

50
00:02:52.100 --> 00:02:55.990
We're going to have a little thing that,
again I wrote this stuff and

51
00:02:55.990 --> 00:03:00.680
I found that sometimes an email address
ends up with some extra junk on it, and

52
00:03:00.680 --> 00:03:04.790
so it's not like this is magic.

53
00:03:04.790 --> 00:03:10.130
This is stuff that I derive, slowly but
surely, looking at my data and mistakes.

54
00:03:10.130 --> 00:03:12.120
Parsing the mail date, that's from before.

55
00:03:13.460 --> 00:03:17.440
Parsing the header, that's from before,
that's going to pull out the name and

56
00:03:17.440 --> 00:03:21.260
email and subject.

57
00:03:21.260 --> 00:03:22.610
Okay so here we go.

58
00:03:22.610 --> 00:03:25.960
So one of the things that I do here is
because I want to run this process over

59
00:03:25.960 --> 00:03:29.905
and over, content.sqlite is
the result of our spidering and

60
00:03:29.905 --> 00:03:34.050
index.sqlite is going to be
the result of our modeling.

61
00:03:34.050 --> 00:03:36.260
So this reads from content and
writes to index.

62
00:03:36.260 --> 00:03:38.787
So this is going to
connect to index.sqLite.

63
00:03:38.787 --> 00:03:42.110
This text_factory str,
that has to do with Unicode.

64
00:03:42.110 --> 00:03:44.600
Cursor, we're going to
wipe this out every time.

65
00:03:44.600 --> 00:03:47.860
So every time we're going to run the
modeling process, because this is where

66
00:03:47.860 --> 00:03:52.190
we're cleaning up our data, we're going to
just wipe out the messages, the senders,

67
00:03:52.190 --> 00:03:55.700
the subjects and the replies and
these are all different tables and

68
00:03:55.700 --> 00:03:59.340
you're going to see things
like integers, primary keys.

69
00:03:59.340 --> 00:04:04.100
So we're going to make the Messages table,
it's going to have the IDs, some guid for

70
00:04:04.100 --> 00:04:06.084
some unique text identifier.

71
00:04:06.084 --> 00:04:09.710
The sent_at which is an integer, the
sender's id which is an integer primary

72
00:04:09.710 --> 00:04:13.630
key, and the subject id, because
sometimes we have many subject ids.

73
00:04:13.630 --> 00:04:17.000
And then the headers and
the body which are both blobs.

74
00:04:17.000 --> 00:04:19.970
And then we have a Senders table.

75
00:04:19.970 --> 00:04:21.450
Each sender has an id and

76
00:04:21.450 --> 00:04:27.530
then the name of the sender and
that's got a unique id so we're keying.

77
00:04:27.530 --> 00:04:30.250
We just threw this stuff into one table
and now we're spreading it across.

78
00:04:30.250 --> 00:04:33.800
We're going to make a Subject table
which is going to have a primary key,

79
00:04:33.800 --> 00:04:38.000
and the subject text, and
then the Replies so that we can keep track

80
00:04:38.000 --> 00:04:41.250
of later which message is
replying to which other message.

81
00:04:41.250 --> 00:04:45.780
And so the first thing we're going to
do is read this mapping.sqlite.

82
00:04:45.780 --> 00:04:50.180
So let me show you what's
in the mapping.sqlite file.

83
00:04:50.180 --> 00:04:52.150
This is our content so
let me close that one.

84
00:04:52.150 --> 00:04:57.460
Let me close that one.

85
00:04:57.460 --> 00:05:00.290
And let me open a different database,
the mapping.

86
00:05:00.290 --> 00:05:03.750
So the mapping.sqlite, this
comes in a zip file.

87
00:05:03.750 --> 00:05:05.670
So it's really actually a tiny database.

88
00:05:05.670 --> 00:05:09.670
For all that matters we probably could
have put these things into a flat file.

89
00:05:09.670 --> 00:05:12.450
But I put them in a database just so
that we can play with it.

90
00:05:12.450 --> 00:05:17.550
And so I mentioned that these
are examples of people that had changed

91
00:05:17.550 --> 00:05:22.380
their names over the course of this
project, which is a multi-year project.

92
00:05:22.380 --> 00:05:27.020
And so I had to have their old names and
their new names, and I got these just

93
00:05:27.020 --> 00:05:31.890
by running the data and
realizing that something popped up.

94
00:05:31.890 --> 00:05:34.740
And so I go wait a sec, it's really the
same person, they just happened to change

95
00:05:34.740 --> 00:05:38.610
their names and they were switching
jobs throughout the process, okay?

96
00:05:38.610 --> 00:05:42.660
And so that was the mapping
of email addresses and

97
00:05:42.660 --> 00:05:44.540
then there's a domain address.

98
00:05:44.540 --> 00:05:47.980
This school and this school turned
out to be the same in our data and

99
00:05:47.980 --> 00:05:50.470
I didn't want to hurt that basically.

100
00:05:50.470 --> 00:05:55.150
And so
that's what's in this mapping.sqlite.

101
00:05:55.150 --> 00:05:59.810
And so all I do is I say select old,
new from DNSMapping.

102
00:05:59.810 --> 00:06:03.540
And then I go through all the rows and

103
00:06:03.540 --> 00:06:08.430
I create a dictionary that maps
the old mail to the new mail.

104
00:06:08.430 --> 00:06:11.940
It's rather complex and long but
it's really just taking the lowercase,

105
00:06:11.940 --> 00:06:13.060
stripping it.

106
00:06:13.060 --> 00:06:15.560
And pulling out the first column and

107
00:06:15.560 --> 00:06:18.200
making that the key in my
dictionary versus the value.

108
00:06:21.240 --> 00:06:26.270
That's the key value for the domain names,
and then we do this a similar thing for

109
00:06:26.270 --> 00:06:31.500
the email addresses and we use this 
fixsender to clean up the names of emails.

110
00:06:31.500 --> 00:06:33.080
Go from old to new, and

111
00:06:33.080 --> 00:06:36.010
then we just basically create another
dictionary mapping old to new.

112
00:06:36.010 --> 00:06:38.750
What we don't want to be doing
is reading these two tables

113
00:06:38.750 --> 00:06:40.740
every time we have to look this stuff up.

114
00:06:40.740 --> 00:06:45.680
And it's not that much data so ultimately
these lines of code read that and

115
00:06:45.680 --> 00:06:49.110
that's why I actually connect,
close the cursor afterwards.

116
00:06:49.110 --> 00:06:53.110
Cause this is just the cursor before the
program starts to read these mappings in,

117
00:06:53.110 --> 00:06:55.560
put them in memory structures
to save us some time.

118
00:06:58.360 --> 00:07:00.950
Okay so now we're going to do 
the main event.

119
00:07:00.950 --> 00:07:05.130
So we're going to connect to the database,
content.sqlite again for

120
00:07:05.130 --> 00:07:07.630
the unit code to make a factory,
get ourselves a cursor.

121
00:07:08.750 --> 00:07:11.280
And then what we're going to do
is we're going to read through,

122
00:07:11.280 --> 00:07:15.720
first read through all of the email
messages and get the email addresses and

123
00:07:15.720 --> 00:07:18.680
then put them in a Python list.

124
00:07:18.680 --> 00:07:19.320
Okay?

125
00:07:19.320 --> 00:07:23.510
And I'm going to load all those up and
again I just want to make it so

126
00:07:23.510 --> 00:07:24.600
this sits in memory.

127
00:07:24.600 --> 00:07:26.370
Because I don't want to have
to read this over and over.

128
00:07:26.370 --> 00:07:31.180
So I'm reading through the entire thing
once and cleaning up with this fixsender

129
00:07:31.180 --> 00:07:34.520
which is taking the raw
email address that we got from

130
00:07:34.520 --> 00:07:39.310
the API call in the beginning and making
an email address that is consistent

131
00:07:39.310 --> 00:07:41.370
and canonical.

132
00:07:41.370 --> 00:07:44.650
And so I append that, I make myself
a list, I print something out.

133
00:07:45.860 --> 00:07:47.910
Okay, now we're going to
go through everything.

134
00:07:47.910 --> 00:07:50.690
So we're selecting the headers and
the body and

135
00:07:50.690 --> 00:07:54.790
the sent_at,
ordered by the sent_at from the messages.

136
00:07:54.790 --> 00:07:57.300
And we have a dictionary of senders,
a dictionary of subjects,

137
00:07:57.300 --> 00:07:59.080
a dictionary of guids.

138
00:07:59.080 --> 00:08:04.230
And that's so that I can keep track of
the emerging primary keys of these things,

139
00:08:04.230 --> 00:08:05.420
again, trying to be efficient.

140
00:08:06.450 --> 00:08:08.560
So now, this is the main loop.

141
00:08:08.560 --> 00:08:12.880
It is basically going to read the row,
which is headers, body, sent_at.

142
00:08:14.880 --> 00:08:17.363
We're going to parse the headers
with my parsing-header function.

143
00:08:20.914 --> 00:08:26.750
If there's an error in parseheader,
I get none back.

144
00:08:26.750 --> 00:08:31.350
Otherwise I get a 4-tuple which is
the global unique ID, the sender,

145
00:08:31.350 --> 00:08:34.960
the subject, and the sent_at.

146
00:08:34.960 --> 00:08:37.450
Then I apply the sender mapping.

147
00:08:37.450 --> 00:08:42.530
This is, mapping is a dictionary .get,
so is the old sender name and by

148
00:08:42.530 --> 00:08:45.890
default of the old sender is not in there
and the default is also the sender's name.

149
00:08:45.890 --> 00:08:47.430
That's the email address.

150
00:08:47.430 --> 00:08:51.830
So this is my way of taking many email
addresses and mapping them to one.

151
00:08:51.830 --> 00:08:53.330
Just how I constructed that mapping.

152
00:08:55.200 --> 00:08:58.050
I'm going to add for a counter, just so

153
00:08:58.050 --> 00:09:01.900
that I can every 250th record
I can print something.

154
00:09:04.660 --> 00:09:05.640
And some error checking.

155
00:09:07.640 --> 00:09:10.050
I'm looking to see if I
already have a primary key,

156
00:09:10.050 --> 00:09:12.780
if I've already inserted
a sender in this run.

157
00:09:12.780 --> 00:09:17.030
Senders is a primary key to email address,

158
00:09:17.030 --> 00:09:21.170
senders more of email address, subject ID,
did I put the subject in already?

159
00:09:21.170 --> 00:09:24.810
Again, I'm data modeling into
a bunch of many-to-one things.

160
00:09:24.810 --> 00:09:28.040
And whether or
not I've got a guid in there or not.

161
00:09:28.040 --> 00:09:32.250
And so I'm keeping track of these
because it's just not that much data.

162
00:09:32.250 --> 00:09:34.425
There's only 50,000 of them.

163
00:09:34.425 --> 00:09:36.660
So if these start out at empty.

164
00:09:36.660 --> 00:09:40.070
If the sender starts out empty here.

165
00:09:40.070 --> 00:09:46.320
So the first time I see a record and
I retrieve csev@umich.edu was what this is.

166
00:09:46.320 --> 00:09:49.250
If I retrieve it, I'm
not going to get an ID.

167
00:09:49.250 --> 00:09:53.670
And so I'm going to say, if it's none,
which is the default here of course,

168
00:09:53.670 --> 00:09:56.660
I'm going to say insert or ignore
into Senders.

169
00:09:57.700 --> 00:09:59.650
The insert or ignore
probably wouldn't matter,

170
00:09:59.650 --> 00:10:01.080
but I'm always really conservative.

171
00:10:01.080 --> 00:10:04.100
insert or ignore into Senders and
I stick the sender in there.

172
00:10:04.100 --> 00:10:05.240
And that's going to get me the ID.

173
00:10:05.240 --> 00:10:07.320
I have to commit.

174
00:10:07.320 --> 00:10:12.480
So that then I can immediately do a select
to get the autogenerated ID at that point

175
00:10:12.480 --> 00:10:14.730
of the sender that I just inserted.

176
00:10:14.730 --> 00:10:17.000
And then I grab the row.

177
00:10:17.000 --> 00:10:19.120
And then I set the sender
ID to be that row.

178
00:10:19.120 --> 00:10:21.030
And then I stick it in my Senders.

179
00:10:21.030 --> 00:10:25.940
So this is a mapping of email address
to primary key in my Senders table.

180
00:10:27.180 --> 00:10:30.810
And some of this error checking should
never happen because it's not there.

181
00:10:30.810 --> 00:10:33.740
And you'll see the same thing
happening for the subject ID.

182
00:10:33.740 --> 00:10:37.270
If I don't have a primary key for the
subject, I'm going to insert and ignore,

183
00:10:37.270 --> 00:10:42.550
commit it, pull that primary key back out,
and then set it in my subject ID.

184
00:10:42.550 --> 00:10:44.630
So that I don't have to do this.

185
00:10:44.630 --> 00:10:46.500
These things tend to grow and

186
00:10:46.500 --> 00:10:50.190
I'll be getting these things out
of the dictionary in the future.

187
00:10:50.190 --> 00:10:54.620
So it will insert it once and so

188
00:10:54.620 --> 00:10:58.020
now I have in effect all
the primary keys and

189
00:10:58.020 --> 00:11:01.690
all the foreign keys with guids and
all these things.

190
00:11:01.690 --> 00:11:04.660
And so I'm going to insert or ignore
into Messages.

191
00:11:04.660 --> 00:11:10.440
The guid, the sender ID, the subject ID,
sent_at, headers, and the body.

192
00:11:10.440 --> 00:11:11.650
And I'll put all that stuff in.

193
00:11:11.650 --> 00:11:13.690
And this is pretty straightforward,

194
00:11:13.690 --> 00:11:15.800
except that I'm going to
call this thing called zlib.

195
00:11:15.800 --> 00:11:17.860
And I'm going to compress, so

196
00:11:17.860 --> 00:11:21.870
the data in these rows is not actually
going to be the messages themselves.

197
00:11:21.870 --> 00:11:23.780
But instead I'm going to compress them.

198
00:11:23.780 --> 00:11:27.960
And you'll see later when I read them,
I have to manually uncompress them.

199
00:11:27.960 --> 00:11:31.850
And I'm then going to find out what
the ID, the primary key ID, and

200
00:11:31.850 --> 00:11:35.590
then I'm going to make this guids array so

201
00:11:35.590 --> 00:11:41.260
that that message, I get the actual, this
is the primary key for a particular guid.

202
00:11:41.260 --> 00:11:43.460
GUID stands for Global Unique ID.

203
00:11:43.460 --> 00:11:45.690
It's kind of a hash value of this thing.

204
00:11:45.690 --> 00:11:47.790
And so that is the loop.

205
00:11:47.790 --> 00:11:51.070
And when I'm all said and done,
I'm going to have a table of senders.

206
00:11:51.070 --> 00:11:54.630
I'm going to have a table of subjects,
and then a table of messages, and

207
00:11:54.630 --> 00:11:55.870
I close the whole thing.

208
00:11:55.870 --> 00:11:58.450
So let me run that.

209
00:12:00.930 --> 00:12:03.105
First remember about gmodel.py.

210
00:12:03.105 --> 00:12:08.574
Is every time you start it.

211
00:12:08.574 --> 00:12:15.091
it blasts the index.sqlite.

212
00:12:15.091 --> 00:12:19.429
Starts over, loads all these things,
it loaded 29 email mappings,

213
00:12:19.429 --> 00:12:22.984
one domain name mapping, and
all of the different senders.

214
00:12:22.984 --> 00:12:27.906
Which means by this point, it read
through the content.sqlite once to make

215
00:12:27.906 --> 00:12:30.370
me a mapping of all those things.

216
00:12:30.370 --> 00:12:33.210
So now you see it's working its
way through every single record.

217
00:12:33.210 --> 00:12:36.800
And we're going to have about
55,000 of these things.

218
00:12:36.800 --> 00:12:39.610
And I'm printing out every 250th record.

219
00:12:39.610 --> 00:12:41.480
So you see this every 250.

220
00:12:41.480 --> 00:12:43.160
So right now we're doing a 
bunch of work, and

221
00:12:43.160 --> 00:12:46.565
if your hard drive is going to
start spinning for a while.

222
00:12:46.565 --> 00:12:50.170
This is a very fast computer,
your computer might run this very slow.

223
00:12:50.170 --> 00:12:54.920
Some people reported that this process
of reading this gigabyte of data and

224
00:12:54.920 --> 00:12:59.150
doing all this model creation and
writing and stuff it takes a while.

225
00:12:59.150 --> 00:13:03.500
It could take 20 minutes, it could take
30 minutes, so we'll pause here and

226
00:13:03.500 --> 00:13:07.360
use the magic of video editing to get
to the point where this all finishes.